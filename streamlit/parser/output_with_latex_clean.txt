--- Page 1 ---
Counting Locally Optimal Tours in the TSP Bodo Manthey1 and Jesse van Rhijn1 1Department of Applied Mathematics, University of Twente October 25, 2024 We show that the problem of counting the number of 2-optimal tours in instances of the Travelling Salesperson Problem (TSP) on complete graphs is #P-complete. In addition, we show that the expected number of 2-optimal tours in random instances of the TSP on complete graphs is O(1.2098n√ n!). Based on numerical experiments, we conjecture that the true bound is at most O( √ n!), which is approximately the square root of the total number of tours. 1 Introduction The Travelling Salesperson Problem is among the best-studied problems in computer science. It can be stated compactly: given a weighted graph G = (V, E) with edge weights w : E →R, find the Hamiltonian cycle (tour) on G with the smallest total weight. The TSP is a classic example of a hard optimization problem, being even among Karp’s original 21 NP-hard problems [24]. Owing to this hardness, practitioners often turn to approximate methods. One extremely successful method is local search [26]. This is a general optimization framework where one modifies an existing (sub-optimal) solution into a better solution. The simplest local search heuristic for the TSP is 2-opt [2]. This heuristic takes as its input a tour T, and finds two sets of two edges each, {e1, e2} ⊆T and {f1, f2} ⊈T, such that exchanging {e1, e2} for {f1, f2} yields again a tour T ′, and the total weight of T ′ is strictly less than the total weight of T. This procedure is repeated with the new tour, and stops once no such edges exist. The resulting tour is said to be locally optimal with respect to the 2-opt neighborhood. A convenient way to view 2-opt (and other local search heuristics) is via the transition graph T . This directed graph contains a node for every tour of G. An arc (T1, T2) exists in T if and only if T2 can be obtained from T1 by a 2-opt step and T2 has strictly lower cost than T1. The sinks of T are exactly the locally optimal tours of G. A run of 2-opt can then be characterized by a directed path through T ending in a sink. Much research has previously focused on understanding the running time of 2-opt [11, 18, 19, 27, 28] and its approximation ratio [8, 17, 18, 21, 25]. On the other hand, little is known about the structure of T . In this paper, we are concerned with counting the number of sinks of T , which is equivalent to counting the number of 2-optimal tours in the instance represented by T . There are practical reasons to study the transition graphs of local search heuristics. First, observe that the transition graph of 2-opt for the random TSP instances we consider is a type of random directed acyclic graph. A run of 2-opt can be viewed as a path through this random DAG, so that the the length of the longest path in T is an upper bound for the number of iterations 2-opt can perform. This upper bound is however rather crude: If we consider a run of 2-opt with a random initialization, then the probability that we start the run on a node of the longest path is likely small. If most paths are much shorter, then this can provide a better explanation for the practical running time of 2-opt than only studying the longest path. Structural results on the transition graph may in addition have implications for the running time of metaheuristics. In particular, 2-opt is often used as the basis of simulated annealing, a physics-inspired metaheuristic [2, Chapter 8]. It has long been known that the structure of the transition graph strongly influences the running time of this algorithm. Structural parameters of this graph often enter convergence results and running time estimates [20, 22, 29]. A recent result by Chen et al. [12] especially illustrates 1 arXiv:2410.18650v1  [cs.DS]  24 Oct 2024 

--- Page 2 ---
this point. They showed that the Metropolis process (in essence, simulated annealing at a constant temperature) is unable to find even very large planted cliques in an Erd˝os-R´enyi random graph. Their analysis hinges on several structural results on cliques in such random graphs. The result by Chen et al., as well as the preceding result by Jerrum [22], deals with the purely discrete problem of finding cliques. However, simulated annealing is often applied to weighted problems [1], which yields significant challenges in understanding the transition graph. We believe that understanding more about the structure of transition graphs is key to proving rigorous results on simulated annealing for weighted problems. Results We start by showing that the problem of counting 2-optimal tours is #P-complete, even on complete weighted graphs. Recall that #P is the counting analogue to NP, asking not whether a solution exists but how many solutions exist. A formal definition of #P is provided in Section 2. Our result is in fact slightly stronger. To state it in full, we need the notion of a path cover. A set of paths P in a graph G is a path cover if every vertex of G is contained in exactly one path of P. We then have the following. Theorem 1.1. Let f2-opt be a function that maps a complete weighted graph on the vertex set V to the number of 2-optimal tours on this graph. Using |V | calls to f2-opt, we can compute the number of path covers of size ℓfor each 1 ≤ℓ≤|V | in polynomial time, using f2-opt as an oracle. This result yields #P-hardness of #2Opt on complete graphs as a corollary. This counting problem asks the question: Given a weighted graph G, how many 2-optimal tours are there on G? Note that counting the number of Hamiltonian cycles is trivial on complete graphs, whereas hardness of counting 2-optimal tours in the same setting is not immediately obvious. Theorem 1.2. #2Opt is #P-complete, even on complete graphs. We note that the result remains true for metric TSP instances on complete graphs, which can be seen to hold by adding a sufficiently large number to every edge weight of the original instance. While counting 2-optimal tours on complete graphs is thus likely intractable in general, we may still wonder about the average case. In the case where the edge weights are given by independent uniformly distributed random variables, we obtain the following upper bound on the number of 2-optimal tours. Theorem 1.3. Let G be a complete graph on n = 2k + 1 vertices, with edge weights drawn independently from U[0, 1] for each edge. Then the expected number of 2-optimal tours on G is bounded from above by O  1.2098n√ n!  . In the process of proving Theorem 1.3 we obtain a link between the number of 2-optimal tours and the probability that all entries of a multivariate normal random vector are positive. This quantity is also known as the positive orthant probability. To estimate this probability we prove the following theorem. Theorem 1.4. Let X be a multivariate normal vector with zero mean and covariance matrix Σ. The positive orthant probability P(Rd +) = P(X ∈Rd +) satisfies P(Rd +) ≤ exp  1 2 Pd i=1 Σ−1 ii  E h X2 i  Rd + i 2d−1ed/2 . In particular, if the diagonal elements of Σ−1 are each Σ−1 ii = 1, then P(Rd +) ≤2−d+1e−d/2 exp 1 2E h ∥X∥2 2  Rd + i . Theorem 1.4 makes no assumptions on the covariance matrix Σ, and thus holds for any set of zero-mean multivariate normal variables. Hence, it may be of independent interest in applications where bounds on positive orthant probabilities are necessary. 2 

--- Page 3 ---
2 Preliminaries 2.1 Notation and Definitions We start with some notational shorthand. Given a symbol a, we write am for the string consisting of m copies of a. Throughout, log(·) denotes the logarithm to base 2. We denote the positive orthant of Rd by Rd + = {x ∈Rd | xi > 0, i ∈[d]}. The negative orthant Rd −is defined similarly. Let G = (V (G), E(G)) be a simple graph. For T a tour through G, we call the edges of T the tour-edges and the edges of E(G) \ T the chord-edges. A 2-change on G then removes two tour-edges from T and adds two chord-edges to T. For a fixed tour, if two tour-edges are removed then there is only one choice of chord-edges that yields a new tour. Thus, we can characterize a 2-change fully by the tour-edges it removes. If a 2-change removes the tour-edges e and f we denote this 2-change by ST (e, f), omitting the subscript T when the tour is clear from the context. We say that two 2-changes on T are chord-disjoint if they have no chord-edges in common. Given a set S of 2-changes, we define P(S) = {{e, f} | ST (e, f) ∈S} as the set of pairs of tour-edges that participate in the 2-changes in S. For e ∈T, we define ke(S) = |{p ∈P(S) | e ∈p}|, the number of 2-changes in S in which e participates. For each of these quantities, we may omit the argument S whenever the set meant is clear from context. Counting Complexity For our complexity results, we state the definitions of #P and #P-completeness taken verbatim from Arora and Barak [5]. Definition 1. A function f : {0, 1}∗→N is in #P if there exists a polynomial p : N →N and a polynomial-time Turing machine M such that for every x ∈{0, 1}∗, f(x) =  n y ∈{0, 1}p(x) | M(x, y) = 1 o. For completeness, we need to recall the complexity class FP, which is the functional analogue to P. This means that FP is the set of functions f : {0, 1}∗→{0, 1}∗computable by a polynomial-time deterministic Turing machine. Moreover, we denote by FPf the set of such functions where the Turing machine additionally has access to an oracle for f. Definition 2. A function f is #P-complete if it belongs to #P and every g ∈#P is in FPf. By this definition, if we can solve some #P-complete problem in polynomial time, then we can solve every problem in #P in polynomial time. 2.2 Multivariate Normal Distribution We require some basic facts about multivariate normal distributions. Let µ ∈Rd and let Σ ∈Rd×d be symmetric and positive definite. The multivariate normal distribution N(µ, Σ) is defined by the probability density function f(x) = exp  −1 2(x −µ)T Σ−1(x −µ)  (2π)d/2√ det Σ (1) with support Rd. Let X ∼Nd(µ, Σ). The positive orthant probability of X is the probability that X falls in the positive orthant Rd +. When µ = 0 this quantity is also referred to simply as the orthant probability, without specifiying which orthant, as each orthant is related by flipping the sign of a set of coordinates. Orthant probabilities are closely related to the truncated multivariate normal distribution. Let a, b ∈Rd with ai < bi for each i ∈[d]. By abuse of notation we write [a, b]d = {x ∈Rd | ai ≤xi ≤bi, i ∈[d]}. The multivariate normal distribution truncated from below by a and from above by b is given by f(x; a, b) =    1 P(X∈[a,b]d) · exp(−1 2 (x−µ)T Σ−1(x−µ)) (2π)d/2√ det Σ , if x ∈[a, b]d, 0, otherwise. (2) 3 

--- Page 4 ---
A special case of the truncated normal distribution is the half-normal distribution, which is obtained by setting ai = 0 and bi = ∞for all i, and taking µ = 0 and Σ = diag(σ2 1, . . . , σ2 d). The moments of the truncated multivariate normal distribution are significantly harder to compute than those for the non-truncated distribution. Nevertheless, there are some elegant results in the literature. We need the following result due to Amemiya [4]. Theorem 2.1 ([4, Theorem 1]). Let X be distributed according to a d-dimensional truncated multivariate normal distribution with zero mean and covariance matrix Σ, with each variable truncated only from below at zero. Then for each i ∈[d], d X j=1 Σ−1 ij E[XiXj] = 1. There are also explicit formulae for the second-order moments of this distribution. We use a formula by Manjunath and Wilhelm [6], adapted to our purposes. Theorem 2.2 ([6, adapted from Equation (16)]). Let X be distributed according to a d-dimensional truncated multivariate normal distribution with zero mean and covariance matrix with entries σij, with each variable truncated only from below at zero. Then for each i ∈[d], E[X2 i ] = σii + d X k=1 X q̸=k σik  σiq −σkqσik σkk  Fkq(0, 0), where Fij denotes the joint marginal distribution of (Xi, Xj). 3 Complexity of Counting 2-Optimal Tours We now proceed to show hardness of counting 2-optimal tours on complete graphs. We start by recalling the notion of a path cover. Given a simple graph G = (V, E), a path cover P of G is a collection of vertex-disjoint paths such that every v ∈V belongs to exactly one path of P. The size of P is the number of paths in P. Note that a path cover of size 1 is equivalent to a Hamiltonian path, and that a path cover may contain paths that consist of a single vertex. From an instance G = (V, E) of #HamPath we construct a family of instances Gm = (V ∪S, E ∪F) of #2Opt for m ≥|V | + 1. First, we add a new set S of vertices to G′, where |S| = m ≥|V | + 1. To ensure that the reduction is polynomial-time computable, we also require m ≤2|V |; the reason for this choice will be apparent shortly. The edges of Gm are the edges of G, which are assigned a weight of 0 plus the set of edges F, which contains: • all missing edges between the vertices of V , with weight M, which we call non-edges; • all edges between the vertices of S, with weight N, which we call S-edges; • all edges between the vertices of V and the vertices of S, with weight L, which we call (V, S)-edges. The relationship between the edge weights is as follows: we set M ≫N = 2L. The precise values of these numbers are not important. See Figure 1 for a schematic depiction of the reduction. By this construction, Gm is a complete graph on |V | + m vertices. We claim that by computing the number f2-opt(Gm) of 2-optimal tours on Gm for m ∈{|V | + 1, . . . , 2|V |} we can compute the number of path covers of G of size 1 ≤ℓ≤|V |. To that end, we first characterize the 2-optimal tours on Gm. Lemma 3.1. A tour T through Gm is 2-optimal if and only if it contains no non-edges. Proof. To begin, we note that since |S| > |V |, any tour must contain at least one S-edge. Now suppose T contains a non-edge uv /∈E, and let ab be an S-edge in T. Assume these vertices are traversed in the written order on T. Then we replace uv and ab by ua and vb, a 2-change which decreases the tour length by M + N −2L > 0. Hence, T is not 2-optimal, proving one direction. For the other direction, suppose T contains no non-edges. Since M is much larger than N or L, an improving 2-change cannot add any non-edges to the tour. Any 2-changes on T must then involve only edges of G, S-edges and (V, S)-edges. We go case by case, considering the possible types of the edges removed by any 2-change on T. 4 

--- Page 5 ---
V S 0 M L L L N N N (a) The reduction we use to prove #P-hardness of #2Opt. The set V represents the vertices of the original graph, and S is the set of m vertices added in the reduction. Each depicted edge is labelled with its weight. Note that in Gm, the non-edges of G are added as well (represented here by the dashed edge). (b) A 2-optimal tour through Gm consist- ing of two segments. Solid black curves represent paths through V , solid gray lines are paths through S, and dotted lines are (V, S)-edges. Figure 1: Schematic depiction of the reduction we use to prove #P-hardness of #2Opt, and of a 2- optimal tour in the image instance. Two S-edges. Since the vertices involved are all vertices of S the added edges are also S-edges, and hence the 2-change does not change the length of the tour at all and is therefore not feasible. Two edges of G. Since these edges have zero weight the tour length cannot decrease, and the 2-change is not feasible. Two (V, S)-edges. There are two possibilities for the added edges. In one case we obtain one S-edge and one edge of G, for an improvement of 2L−N = 0. In the other case we obtain again two (V, S)-edges, again for no improvement. One S-edge ab and one edge uv of G. The added edges are au and bv, both of which are (V, S)-edges and thus of weight L. The tour is thus shortened by N −2L = 0, and the 2-change yields no improvement. One (V, S)-edge au and one edge vw of G. The added edges are av and uw. The added edges are again a (V, S)-edge and an edge of G, yielding no improvement. One (V, S)-edge au and one S-edge bc. The added edges consist of one (V, S)-edge and one S-edge, and there is no change in tour length. These cases cover all possibilities, and hence a tour that contains no non-edges is 2-optimal, concluding the proof. Let T be a 2-optimal tour through Gm. If we remove from T all edges incident to S, then we obtain a path cover of G. We call the size of the resulting path cover the number of segments of T. On the other hand, from any path cover of G, we can construct many 2-optimal tours by connecting the paths in the cover using vertices of S. More formally, we say that a path cover P corresponds to T if we obtain P by removing the edges of T incident to S. Note that two distinct path covers of G correspond to two disjoint sets of 2-optimal tours through Gm, and every 2-optimal tour corresponds to exactly one path cover. The following lemma counts the number of 2-optimal tours that correspond to a single path cover of size ℓ. Lemma 3.2. A path cover of size ℓcorresponds to exactly 2ℓ−1·m!·(m−1)! (m−ℓ)! 2-optimal tours in Gm with ℓ segments. Proof. By Lemma 3.1, the 2-optimal tours are exactly those tours which contain no non-edges. Given a path cover P of size ℓ, we can then construct a 2-optimal tour in Gm as follows. Any tour must visit all vertices in S in some order. Hence, we first fix a tour TS through S; there are 1 2(m −1)! such choices. Next, we break ℓedges of TS; there are  m ℓ  choices of which edges to break. 5 

--- Page 6 ---
We must now insert the ℓpaths of P in place of these broken edges, reconnecting the endpoints of each path to the endpoints of the broken edge it replaces. Note that whenever we perform this operation, there are two possible ways to connect the path. Moreover, there are ℓ! ways to match an endpoint to a broken edge, for a total of 2ℓ· ℓ! ways to insert the paths. Putting the pieces together, we thus have (m −1)! 2 · m ℓ  · 2ℓ· ℓ! = 2ℓ−1 · m! · (m −1)! (m −ℓ)! ways to construct a 2-optimal tour through Gm. Let c(ℓ, m) = 2ℓ−1·m!·(m−1)! (m−ℓ)! , and let C ∈Z|V |×|V | be a matrix with entries Cij = c(i, j + |V |). Recall that ℓruns from 1 to |V | and m runs from |V | + 1 to 2|V |. Lemma 3.3. The matrix C defined above has full rank. Proof. To start, we write out the entries of C explicitly. Letting n = |V |, Cij = 2i−1 · (n + j)! · (n + j −1)! (n + j −i)! . Scaling any row or column of a matrix uniformly does not change its rank. Hence, we multiply column j by 1 (n+j)!·(n+j−1)!, and subsequently multiply row i by 1/2i−1. Finally, interchanging any two rows also does not change the rank of the matrix, and hence we also mirror the rows of the matrix. The resulting matrix C′ has entries C′ ij = 1 (i + j −1)!. To show that this matrix has full rank, we first recall that a square matrix has full rank if and only if its determinant is nonzero. While we could in principle compute the determinant exactly, this is tedious and not necessary for our purposes. Hence, we use a concise argument from analysis to only show det C′ ̸= 0 [31], reproduced here for the sake of completeness. The proof uses the notion of the Wronskian W(x) of a set of functions fj(x), which is the determinant of the matrix with (i, j)-th element f (i) j (x). If the functions are analytic, then W(x) vanishes identically if and only if the functions are linearly dependent [7]. We observe that the determinant of C′ is, up to a sign, the Wronskian of the functions fj(x) = xn+j−1 (n+j−1)! evaluated at x = 1. Since these functions are polynomials of different degrees, they are linearly independent and hence from analyticity of the polynomials it follows that the Wronskian does not vanish identically. By factoring out all the powers of x from the rows and columns, we see that the Wronskian is a power of x multiplied by its value at x = 1, which is det C′ up to a sign. As the Wronskian does not vanish identically, we must have det C′ ̸= 0. Now we proceed to our main algorithmic result, from which #P-completeness of #2Opt follows as a corollary. Theorem 1.1. Let f2-opt be a function that maps a complete weighted graph on the vertex set V to the number of 2-optimal tours on this graph. Using |V | calls to f2-opt, we can compute the number of path covers of size ℓfor each 1 ≤ℓ≤|V | in polynomial time, using f2-opt as an oracle. Proof. For a graph G, let Gm be the complete weighted graph resulting from the reduction described above. Let aℓ(G) be the number of path covers of size ℓ, and let bℓ(Gm) be the number of 2-optimal tours on Gm consisting of ℓsegments. From Lemma 3.2, we have bℓ(Gm) = c(ℓ, m)aℓ(G). We have f2-opt(Gm) = P|V | ℓ=1 bℓ(Gm) = P|V | ℓ=1 c(ℓ, m)aℓ(G). We aim to compute the numbers aℓ(G) for each ℓ∈[|V |]. Let a = (aℓ(G))ℓ∈[|V |], and let b = (f2-opt(Gm))2|V | m=|V |+1. Then the above yields the matrix equation b = CT a. By Lemma 3.3, the matrix C has full rank, and is hence invertible. While C is rather ill-conditioned, the elements of C can be encoded using a number of bits polynomial in |V |+|E|. Thus, after making |V | calls to f2-opt to compute the vector b, we can compute a in polynomial time. The entries aℓof a are, by construction, exactly the number of path covers of size ℓof G. 6 

--- Page 7 ---
Theorem 1.2. #2Opt is #P-complete, even on complete graphs. Proof. Membership in #P is obvious, since the problem of verifying 2-optimality of a tour is in P. For hardness, we rely on the #P-hardness of #HamPath, which was shown by Valiant [30]. Note that the number of Hamiltonian paths through a graph G is exactly the number of path covers of size ℓ= 1. By Theorem 1.1, given oracle access to f2-opt, we can solve #HamPath – and thus every problem in #P – in polynomial time, and hence #2Opt is #P-complete when restricted to complete graphs. 4 Counting 2-Optima in Random Instances While counting 2-optimal tours is in general hard on complete graphs, we can still provide some results for special cases. In this section, we restrict our attention to complete graphs on n = 2k + 1 vertices for some integer k. The weights of the edges of our graphs are drawn independently from the uniform distribution on [0, 1]. The strategy we use is to bound the probability that a given tour is 2-optimal. Since we assume the input graph is complete, this probability is the same for all tours. It then suffices to multiply this probability by the total number of tours, which is 1 2(n −1)!. To bound the probability of a tour T being 2-optimal we find a large set S of mutually chord-disjoint 2-changes on T. We then apply a general result that links the probability of 2-optimality of T to how often each edge of T is used in S (Lemma 4.1). Details of the construction of this set are given in Section 4.2. 4.1 Orthant Probabilities and 2-Optimality Let S be a set of chord-disjoint 2-changes on a tour T on the complete graph on n vertices, and define for x ∈RE gS(x) = exp  − X {e,f}∈P (S) xexf p ke(S)kf(S)  . Now let X = (Xe)e∈T,ke(S)>0 be a sequence of independent half-normal distributed random variables with unit variance. We define the function G(S) = E[gS(X)]. Observe that G is solely a function of S. Lemma 4.1. Let G be a complete graph on n vertices, with each edge of G independently assigned a weight drawn from U[0, 1]. Let T be any tour through G. Let S be a set of chord-disjoint 2-changes on T. Then P(T is 2-optimal) ≤G(S) Y e∈T ke(S)>0 r π 2ke(S). Before moving to a proof, we need a technical lemma. Lemma 4.2. For 1 ≤x ≤2, it holds that 1 2(2 −x)2 ≤e−x2/2. Proof. First, observe that the inequality holds for x = 1, as 1 2 < 1/√e ≈0.6. Next, note that e−x2/2 is strictly convex on (1, ∞). Thus, this function lies entirely above its tangent line at x = 1 for all x > 1. The tangent line is given by x 7→2e−1/2−e−1/2x. It then suffices to show that 1 2(2−x)2 ≤2e−1/2−e−1/2x for x ∈(1, 2]. Indeed, 1 2(2 −x)2 ≤2e−1/2 −e−1/2x ⇐⇒2  1 −1 √e  −  2 −1 √e  x + 1 2x2 ≤0, which holds for x ∈[2 −2/√e, 2] ⊃(1, 2]. Proof of Lemma 4.1. Let S be a 2-change on T and write ∆(S) for the improvement in tour length due to S. Then T is 2-optimal if and only if for all possible 2-changes S on T we have ∆(S) ≤0, and so P(T is 2-optimal) ≤P  ^ S∈S ∆(S) ≤0 ! . 7 

--- Page 8 ---
If we condition on the values of the weights on the edges of T, then, since the 2-changes in S are all chord-disjoint, the events {∆(S) ≤0}S∈S are independent subject to this conditioning. Thus, P(T is 2-optimal | w(e) = se, e ∈T) ≤ Y S∈S P(∆(S) ≤0 | w(e) = se, e ∈T). Consider a 2-change S that involves the tour-edges ei and ej. Then P(∆(S) ≤0 | w(ei) = si, i ∈[n]) = P(X + Y ≥si + sj), where X, Y ∼U[0, 1]. We can directly compute this latter probability, yielding P(X + Y ≥si + sj) = Z 2 si+sj fX+Y (x) dx, where the integrand is the density of X + Y , given by fX+Y (x) =      x, if 0 ≤x ≤1, 2 −x, if 1 < x ≤2, 0, otherwise. Integrating this density, we obtain P(X + Y ≥si + sj) =          1, if si + sj ≤0, 1 −1 2(si + sj)2, if si + sj ≤1, 1 2(2 −(si + sj))2, if 1 < si + sj ≤2, 0, if si + sj > 2. On [0, 2], this function is bounded from above by e− (si+sj )2 2 = e−s2 i /2e−s2 j/2e−sisj. For 0 ≤si + sj ≤1, this follows from the standard inequality 1 + x ≤ex, while for 1 < si + sj ≤2 we use Lemma 4.2. Using this upper bound, we can write P(T is 2-optimal | w(e) = se, e ∈T) ≤ Y {e,f}∈P (S) e−s2 e/2e−s2 f /2e−sesf . Note that for a given edge e ∈T, the factor factor e−s2 e/2 appears ke times. Hence, P(T is 2-optimal | w(e) = se, e ∈T) ≤ Y e∈T e−kes2 e/2 · Y {e,f}∈P (S) e−sesf . We now get rid of the conditioning, P(T is 2-optimal) ≤ Z 1 0 · · · Z 1 0 exp   −1 2 X e∈T ke>0 kes2 e   exp  − X {e,f}∈P (S) sesf  Y e∈T ke>0 dse. We perform a change of variables: let xe = √kese. Next, we let the upper limit of each integral go to infinity; it is easily verified that this leads to a negligible loss in the upper bound. We find P(T is 2-optimal) ≤ Y e∈T ke>0 1 √ke Z Rd + exp   −1 2 X e∈T ke>0 x2 e   exp  − X {e,f}∈P (S) xexf p kekf  dx, where dx = Q e∈T ke>0 dxe. We recognize in this expression the function gS, as well as the un-normalized probability density function of the half-normal distribution. Adding in the appropriate normalization factor of p 2/π for each variable then yields the claim. 8 

--- Page 9 ---
Bounding P(T is 2-optimal) now involves two steps. First, we must construct a set S of chord-disjoint 2-changes such that each edge of T is used in many 2-changes in S. Second, given this set, we must bound G(S). We remark now that G(S) is trivially bounded from above by 1. However, this leaves a factor of about (π/2)n/2. Although this factor is small compared to Q e∈T, ke>0 1 √ ke(S) for the set S we construct, leaving it in is somewhat unsatisfactory. We thus make an attempt to prove a stronger bound for G. Computing G(S) directly is unfeasible. It helps to recast it in terms of a positive orthant probability. Lemma 4.3. For a set S of chord-disjoint 2-changes on a tour T, let k denote the number of tour-edges with ke(S) > 0. Label these edges of T arbitrarily from 1 to k. For any I ⊆[k], the function G(S) is bounded from above by 2|I|· √ det Σ·P  V i∈I Zi > 0  , where (Zi)i∈I is distributed according to a multivariate normal distribution with mean 0 and inverse covariance matrix Σ−1 ∈R|I|×|I| with entries indexed by I, Σ−1 ij = ( 1, if i = j, sij, otherwise, where sij ≤1/ p kikj. Proof. Since gS(x) ≤1 and gS is decreasing in each variable, we can bound gS from above uniformly by setting the coefficients of any subset of the variables to zero. Setting these to zero for all variables outside I then leaves G(S) ≤  2 π |I|/2 Z R|I| + exp   −1 2 X i∈I x2 i ! exp  − X i∈PI(S) xixj p kikj  Y i∈I dxi, where PI(S) is the same as P(S), except we keep only pairs with both elements in I. Observe that e−xixj/√ kikj ≤e−sijxixj, allowing us to replace the coefficients of these products. We now only need to insert the appropriate normalization factor for a multivariate normal distribution. Comparing the resulting expression with Equation (1) completes the proof. Still, computing the positive orthant probability directly is rather difficult. Explicit formulas are known for low-dimensional cases, as well as general recursive formulas [3, 13, 14], but none of these are particularly helpful in bounding G(S). As we only need a nontrivial upper bound, some simplifications are possible. In Theorem 1.4 (restated below), we show that it suffices to bound the expected squared norm of a multivariate normal vector. In the proof of Theorem 1.4, we need another technical lemma. Lemma 4.4. Let S be a random string uniformly chosen from {1, −1}d \ {1d, −1d} for d ≥2. Then we have P(Si + Sj = 0) ≥1 2 for any distinct i, j ∈[d]. Proof. The case d = 2 yields P(S1 + S2 = 0) = 1 ≥1 2; hence, we assume d > 2 in the remainder. Note next that by symmetry, it suffices to consider i = 1, j = 2. The event S1 + S2 = 0 occurs if and only if (S1, S2) is either (1, −1) or (−1, 1). We use the principle of deferred decisions. Suppose that the remaining d −2 variables have been fixed. If the string formed by these remaining variables is equal to neither 1d−2 nor −1d−2, then the outcome of drawing (S1, S2) is unconstrained. There are four outcomes and by symmetry each outcome has equal probability, yielding the claim. If the remaining string is 1d−2, then there are only three possible outcomes for (S1, S2), each with equal probability. Two of these outcomes satisfy S1 + S2 = 0; hence in this case P(S1 + S2 = 0) = 2 3 ≥1 2. The case where the remaining string is −1d−2 is identical. Theorem 1.4. Let X be a multivariate normal vector with zero mean and covariance matrix Σ. The positive orthant probability P(Rd +) = P(X ∈Rd +) satisfies P(Rd +) ≤ exp  1 2 Pd i=1 Σ−1 ii  E h X2 i  Rd + i 2d−1ed/2 . In particular, if the diagonal elements of Σ−1 are each Σ−1 ii = 1, then P(Rd +) ≤2−d+1e−d/2 exp 1 2E h ∥X∥2 2  Rd + i . 9 

--- Page 10 ---
Proof. We prove the first claim, as the second claim follows trivially. For s ∈{−1, 1}d, let Rd s be the orthant corresponding to s, given by the points x ∈Rd satisfying sixi > 0, i ∈[d]. With this notation, the positive and negative orthants are given by Rd ± = Rd ±1d. Since Rd = S s∈{±1}d Rd s and the orthants are mutually disjoint, P s∈{±1}d P(Rs) = 1. By symme- try, P(Rd +) = P(Rd −), and so P(Rd +) = 1 2 −1 2 X s∈{±1}d s̸=±1d P(Rd s). (3) Given s ∈{±1}d, define the linear transformation Rs(x) = (sixi)i∈[d]. Any x ∈Rd s can then be written as x = Rs(x′) for some x′ ∈Rd +. Let Σ−1 s denote the matrix with the same entries as Σ−1, but with zeroes on the diagonal and zeroes for any entries (i, j) with si + sj ̸= 0. Now note that for x ∈Rd s, 1 2xT Σ−1x = 1 2 d X i=1 d X j=1 Σ−1 ij xixj = 1 2 d X i=1 d X j=1 Σ−1 ij x′ ix′ j − d X i=1 d X j=1 Σ−1 s,ijx′ ix′ j, since only the terms satisfying si + sj = 0 change sign under Rs. Thus, we have P(Rd s) = 1 (2π)d/2√ det Σ Z Rd + e−1 2 xT Σ−1x exp   d X i=1 d X j=1 Σ−1 s,ijxixj  dx = E  exp   d X i=1 d X j=1 Σ−1 s,ijXiXj    Rd +  P(Rd +). Inserting this into Equation (3) and rearranging yields P(Rd +) =     2 + X s∈{1,−1}d s̸=±1d E  exp   d X i=1 d X j=1 Σ−1 ij XiXj    Rd +        −1 . Since exp(·) is a convex function, we bound the denominator from below by moving the expectation operator inside the exp(·) using Jensen’s inequality. To shorten our notation, we replace the variables Xi by Zi distributed according to a multivariate normal distribution truncated from below at zero. We abbreviate the expectation with respect to Z by EZ[·]. Then (discarding the 2 in the denominator above) P(Rd +) ≤      X s∈{±1}d s̸=±1d exp  EZ   d X i=1 d X j=1 Σ−1 s,ijZiZj          −1 . Let S be a random string drawn uniformly from {±1}d \ {±1d}. Observe that the sum in brackets above is the same as  2d −2  ES  exp  EZ   d X i=1 d X j=1 Σ−1 S,ijZiZj      . Another application of Jensen’s inequality moves the ES[·] into the exp(·). To simplify the expression yet further, we bound 2d −2 ≥2d−1 for d ≥2. Let Yij(S) be an indicator random variable taking a value of 1 if Σ−1 s,ij > 0 and 0 otherwise. Then Σ−1 S,ij = Yij(S)Σ−1 ij . Note that Yij(S) = 1 if and only if Si+Sj = 0. We then use Lemma 4.4 to obtain ES[Yij(S)] = 10 

--- Page 11 ---
P(Yij(S) = 1) ≥1 2. Using Yij(S), we further rewrite our bound to ES  EZ   d X i=1 d X j=1 Σ−1 s,ijZiZj    = d X i=1 d X j=1 j̸=i ES  EZ  Yij(S)Σ−1 ij ZiZj  = d X i=1 d X j=1 j̸=i ES[Yij(S)]  EZ  Σ−1 ij ZiZj  ≥1 2 d X i=1 d X j=1 j̸=i Σ−1 ij EZ[ZiZj]. The second equality follows from the independence of {Zi}d i=1 and Yij(S). For the final step we use Theorem 2.1, from which we conclude 1 2 d X i=1 d X j=1 j̸=i Σ−1 ij EZ[ZiZj] = 1 2 d X i=1 d X j=1 Σ−1 ij EZ[ZjZj] −1 2 d X i=1 Σ−1 ii EZ[Z2 i ] = d 2 −1 2 d X i=1 Σ−1 ii EZ[Z2 i ]. Putting the pieces together now yields the claim. 4.2 Finding Chord-Disjoint 2-Changes To proceed, we need to construct an appropriate set S of chord-disjoint 2-changes. We provide an explicit construction of such a set. In doing so, we need the following four lemmas to help us characterize when a pair of 2-changes is chord-disjoint. It is convenient for the remainder of the section to assign an orientation to T. Pick an arbitrary vertex of T, and walk along T in an arbitrary direction. We order the edges of T according to the order we encounter them in, labelling the first edge e1, the second e2, and so on. Moreover, we consider these edges directed: If e is incident to u and v and u is encountered before v, then we write e = uv. Lemma 4.5. If two 2-changes share exactly one tour-edge, then they are chord-disjoint. Proof. Let S1 = S(e, f1) and S2 = S(e, f2) be two 2-changes sharing a single tour-edge e = u1u2. Let f1 = v1v2 and f2 = v3v4. Since f1 ̸= f2, these edges can share at most one endpoint. Moreover, by the orientation of T, we can only have v2 = v3 or v1 = v4 The chord-edges involved in S1 are u1v1 and u2v2, while the chord-edges involved in S2 are u1v3 and u2v4. Thus, S1 and S2 only share a chord-edge if v1 = v3 or v2 = v4, which is not possible. Lemma 4.6. If two 2-changes have at most one endpoint in common, then they are chord-disjoint. Proof. Let S1 and S2 be two 2-changes. Note that by assumption, S1 and S2 cannot share any tour-edges, since then they would have two endpoints in common. If the 2-changes have no endpoints in common, then the lemma is obviously true. Assume then that the 2-changes have one endpoint in common. Let e1 and f1 be removed by S1, and e1 and f2 be removed by S2. Without loss of generality, assume e1 and e2 have an endpoint in common. We write e1 = v1v2 and e2 = v2v3. Let f1 = u1u2 and f2 = u3u4. Note that all of these vertices with different labels are distinct. The chord-edges added by S1 are then v1u1 and v2u2, while those added by S2 are v2u3 and v3u4. Observe that these are four distinct edges, concluding the proof. Lemma 4.7. Let T1 and T2 be two successive sub-paths of a tour T, both containing an even number of edges. Any two 2-changes which are each formed by removing one edge in T1 and one edge in an even position along T2 are chord-disjoint. 11 

--- Page 12 ---
T1 T2 T3 T4 T5 T6 T7 T8 Figure 2: Colors of the edges in the tour T at stage t = 3, for n = 24 + 1. The dotted lines are drawn to show the boundaries of each segment Ti more clearly. The segments of the tour are numbered starting at the right and proceeding counterclockwise. The 2-changes we consider in the proof of Lemma 4.9 are then the 2-changes formed from the red edges in Ti (drawn black) and the blue edges in Ti+1 (drawn gray) that appear in even positions along T, for i odd. Note that the last edge along T is drawn dashed to indicate that it is not used in the construction of S. Proof. Let e1, e2 ∈T1 and f1, f2 ∈T2. Consider two distinct 2-changes S1 = S(e1, f1) and S2 = S(e2, f2). Note that if e1 ̸= e2 and f1 ̸= f2, then the edges involved in S1 share at most one endpoint with the edges involved in S2 (namely a common endpoint between two edges in T1), and the conclusion follows from Lemma 4.6. Moreover, if e1 = e2 and f1 = f2, then S1 = S2, so we can ignore this case. It remains to consider the case that S1 and S2 share exactly one tour-edge. The conclusion then follows from Lemma 4.5. Lemma 4.8. Let S1 = ST (e1, f1) and S2 = ST (e2, f2) be two 2-changes with the property that three edges of {e1, e2, f1, f2} form a path disjoint from the remaining edge. Then S1 and S2 are chord-disjoint. Proof. Observe that two edges on the path P must form a 2-change S together. The remaining edge of the path forms a 2-change S′ with some edge e′ vertex-disjoint from the path. It follows that these 2-changes are chord-disjoint, since the chord-edges of S′ both contain vertices not on P while the chord-edges of S only contain vertices of P. Next, we construct a set S of 2-changes such that any two 2-changes in S are chord-disjoint, and most of the edges of T participate in many 2-changes in S. The construction we provide here works for complete graphs with n = 2k + 1 vertices for some integer k. The construction of S proceeds as follows. Recall that we ordered the edges of T as (e1, e2, . . . , en). We define the following process on T, occurring in stages. At stage t we divide the tour into 2t equal segments {T1, . . . , T2t}, starting at e1. In each stage, we color all the edges in each odd segment red and the edges in each even segment blue. The only exception to this rule is the last edge en, which we color black; this edge is not used to form any 2-changes. See Figure 2 for an illustration at stage t = 3. At each stage we consider the 2-changes formed by the red edges in each odd segment Ti together with the even blue edges in its successor segment Ti+1. We say that these are the 2-changes added in stage t, and denote the set of these 2-changes by St. We continue this process for log(n −1) −1 stages. Note that in the final stage, each segment contains two colored edges. Lemma 4.9. The 2-changes in S = Slog n−1 t=1 St are chord-disjoint. Proof. For any two 2-changes in St, chord-disjointness follows from Lemma 4.7. It thus remains to show this for some S1 ∈St1 and S2 ∈St2. Assume w.l.o.g. that t1 < t2. In the following, we write S1 = ST (e1, f1) and S2 = ST (e2, f2). We consider the number of shared vertices between S1 and S2. Since the case of two shared vertices is the hardest to analyze, we consider it last. By Lemma 4.6, if S1 and S2 share at most one vertex, then the 2-changes are chord-disjoint. If S1 and S2 share three vertices, then they have exactly one edge in common. By Lemma 4.5, they are then chord-disjoint. 12 

--- Page 13 ---
Next, if the two 2-changes have four vertices in common, then either the edges of S1 and of S2 form a cycle, or S1 = S2. The former case is only possible if n = 4, but we assume that n is odd throughout. Thus, assume S1 = S2. By construction, S1 and S2 both remove one red and one even blue edge from successive segments. Observe that at any stage t ≥2, if e and f participate in the same 2-change, then by construction e and f are both red in every stage t′ ≤t. Thus both edges removed in S2 are red in stage t1. This is impossible, as S1 removed the same pair of edges as S2 in stage t1, and every 2-change of St1 removes one red and one blue edge. If S1 and S2 have three vertices in common, then the edges must form a path. This path must be e1e2f1f2 up to interchanging the indices, since the tour-edges of a 2-change cannot share any vertices. By our chosen orientation e1 must be red in stage t1 and e2 must be red in stage t2. Then f1 and f2 are both blue in these respective stages. But blue edges are only used in a 2-change when they are even, and f1 and f2 cannot both be even: a contradiction. Lastly, assume that S1 and S2 share two vertices. If these vertices are both incident to the same edge in both 2-changes, then S1 and S2 share exactly one edge, and so once again by Lemma 4.5 S1 and S2 are chord-disjoint. Thus, there are two cases: either e1 and e2 share an endpoint, as do f1 and f2; or three edges among {e1, f1, e2, f2} lie on a path disjoint from the last edge. The second case follows directly from Lemma 4.8. In the first case, assume w.l.o.g. that e1 comes before e2 in T and that e1 is red in stage t1. Then f1 is blue in stage t1, and thus f1 is an even edge. Since e2 directly follows e1 and we assume f1 and f2 share a vertex, we also know that e2 is red in stage t2 and f2 is blue in stage t2. But in constructing S blue edges are only used in 2-changes when they occur in even positions along T, and f1 and f2 cannot both be even; a contradiction. Note that this part of the analysis does not use the fact that t1 < t2, and thus if we interchange the indices, the same reasoning goes through. Hence, this case can be excluded. This concludes the case analysis. We have thus shown that two 2-changes from two different stages must be chord-disjoint, and therefore S consists only of chord-disjoint 2-changes. We now determine how often each edge of T is used in S. Lemma 4.10. For S as constructed above, we have {ke(S)}e∈T = {0, 1, 2, . . . , n −3}. Moreover, there are two edges with ke(S) = 0 and two edges with ke(S) = n−1 2 . Proof. We maintain the same order on the edges of T as used in the construction of S. Using this order, we call an edge even if it appears in an even position in this order, and odd otherwise. Note that the last edge en is not considered in the construction of S, and so ken = 0. For the remainder of the proof, we consider T with en removed. For convenience, denote by kt e the number of 2-changes that e participates in at stage t, so that ke = Plog n−1 t=1 kt e. We observe the following property of S. Fact. Consider stage t in the construction of S. If an edge e is red in stage t, then kt e = n/2t+1. If e is blue, then kt e = n/2t if e is even, and kt e = 0 otherwise. For any edge of T, we can count the number of 2-changes of S it participates in as follows. Construct a rooted directed binary tree H, where the nodes of H are sub-paths of T. The root of H is T itself, while the children of any node P of H are the first and the second halves of the edges in P under the ordering of the edges of T, labelled P1 and P2 respectively. Thus, the children of T are P1 = {e1, . . . , e(n−1)/2} and P2 = {e(n−1)/2+1, . . . , en−1}. We moreover label the arcs of H. If P1 and P2 are the children of a node P as described above, then the arc a1 = (P, P1) gets a label L(a1) = 1, while a2 = (P, P2) gets a label L(a2) = 0. We construct H in this way from the root, continuing until H has depth log(n −1) −1. (We define the depth of a node v in a rooted directed tree as the number of arcs in the directed path from the root to v. The depth of the tree itself is the largest depth among all nodes of the tree.) Then the nodes at depth t of H are the parts into which T is partitioned at stage t. Note that the leaves of H each contain two successive edges of T. Let a = (P, Q) be an arc in H with L(a) = 1. From the construction of S, it follows that any edge e ∈Q is colored red in the stage corresponding to the depth of Q. Conversely, if L(a) = 0, then Q is colored blue in this stage. For each leaf P of H, we then consider the path P(v) = Ta1P1a2 . . . alog(n−1)−1Q from the root to this leaf. Following this path, we collect the labels of the arcs along this path into a string x(Q), so x(Q) = L(a1)L(a2) . . . L(alog(n−1)−1). For e ∈Q, we set xe = x(Q). 13 

--- Page 14 ---
Given xe for some edge e ∈T, we know that e is red in stage t if and only if xe(t) = 1. We thus know exactly in which stages e is colored red, and in which it is colored blue. Using this information together with the fact above, we can derive formulae for ke for any e ∈T. There are two distinct cases. Case 1: e odd. Since e is odd, it only participates in any 2-change when it is colored red. Thus, stage t contributes xe(t) · (n −1)/2t+1 2-changes, and so we count ke = (n −1) log(n−1)−1 X t=1 xe(t) · 1 2t+1 = log(n−1)−1 X t=1 xe(t) · 2log(n−1)−1−t = log(n−1)−2 X j=0 xe(log(n −1) −1 −j) · 2j. Note that for a given bit string xe, this is simply the decimal expansion of the binary number represented by xe. Since every bit string of length log(n −1) −1 is present for some odd edge (there are 2log(n−1)−1 leaves in H and each leaf corresponds to a distinct string), we find that {ke | odd e ∈T} = {0, 1, . . . , (n −1)/2 −1}. Case 2: e even. An even edge contributes (n −1)/2t+1 2-changes at stage t if it is red, and (n −1)/2t 2-changes if it is blue. Thus, the contribution at this stage is (n −1)/2t −xe(t) · (n −1)/2t+1, and so we have ke = (n −1)   log(n−1)−1 X t=1 2−t − log(n−1)−1 X t=2 xe(t) · 1 2t+1   = n −3 −n −1 2 · log(n−1)−1 X t=1 xe(t) · 1 2t = n −3 − log(n−1)−2 X j=0 xe(log(n −1) −1 −j) · 2j. As in the previous case, we recognize here the decimal expansion of xe in the second term. Thus, {ke | even e ∈T} = {(n −1)/2 −1, (n −1)/2, . . . , n −2, n −3}. 4.3 Putting the Pieces Together We return to the positive orthant probability by constructing an inverse covariance matrix Σ−1 corre- sponding to S according to Lemma 4.3. In the following, we sort the edges of T by decreasing value of ke(S). Observe that the first d = (n −3)/2 edges of T in this order each form 2-changes with one another in S. Note that d is an integer, as n = 2k +1 is odd. The entries of Σ−1 corresponding to these 2-changes are Σ−1 ij = 1/ p kikj ≥ 1 n−3. Thus, the inverse covariance matrix Σ−1 constructed from S is upper-left triangular, except with ones on the diagonal. We can then write it in block form, Σ−1 = ˜Σ−1 A AT I  , where the diagonal entries of ˜Σ−1 ∈Rd×d are each 1, and the off-diagonal entries each satisfy ˜Σ−1 ij =≥ 1 n−3 = 1 2d. We consider the matrix ˆΣ−1, which is identical to ˜Σ−1, but with the off-diagonal entries replaced by 1 2d. Comparing ˆΣ−1 to Lemma 4.3, we proceed to bound the positive orthant probability associated with ˆΣ−1. A trivial bound for this probability is 2−d. Lemma 4.11 therefore represents a non-trivial, if modest, improvement. Lemma 4.11. Let X be distributed according to Nd(0, ˆΣ), where ˆΣ−1 ∈Rd×d has unit diagonal entries and off-diagonal entries 1 2d. The positive orthant probability of X is bounded from above by O  2−de−2d 9π  . 14 

--- Page 15 ---
Proof. It suffices to bound E[∥X∥2|Rd +] and use Theorem 1.4. By symmetry of ˆΣ−1 the marginal densities of the entries of X are all identical. Hence, E[∥X∥2 | Rd +] = d · E[X2 1 | Rd +]. To compute this expected value we use Theorem 2.2, which yields E[X2 i | Rd +] = σii + d X k=1 X q̸=k σik  σiq −σkqσik σkk  Fkq(0, 0), where σij denotes the i, j-entry of ˆΣ, and Fkq(x, y) is the joint marginal distribution of (Xk, Xq) condi- tional on X ∈Rd +. The marginal distributions are given by a rather compact expression, since we only evaluate them at the origin. Using the conditional density of X as given in Equation (2), Fkq(0, 0) = 1 (2π)d/2p det ˆΣ · 1 P(Rd +) · Z Rd−2 + exp  −1 2xT ˆΣ−1 (kq)x  dx, where ˆΣ−1 (kq) is simply ˆΣ−1 with the kth and qth rows and columns removed. This expression can be simplified further as follows. For arbitrary m ∈N, let Σ−1 m be the m×m matrix with unit diagonal and off-diagonal entries 1 2d. Then ˆΣ−1 = Σ−1 d and Σ−1 (kq) = Σ−1 d−2. Hence, inserting the expression for P(Rd +) and cancelling like terms, we obtain Fkq(0, 0) = R Rd−2 + exp  −1 2xT Σ−1 d−2x  dx R Rd + exp  −1 2xT Σ−1 d x  ≥ R Rd−2 + exp  −1 2xT Σ−1 d−2x  dx R Rd−2 + exp  −1 2xT Σ−1 d−2x R ∞ 0 e−1 2 x2 dx 2 = 2 π . Next, we need to compute the entries of ˆΣ and the determinant det Σ−1 d . Note that Σ−1 d = D + 1 2deeT , where D =  1 −1 2d  I and e is the all-1 column vector. It can then be straightforwardly verified from the Sherman-Morrison formula that det Σ−1 d = 3d −1 2d −1 2d −1 2d d and σij = 2d 2d −1 · ( 1 − 1 3d−1, if i = j, − 1 3d−1, otherwise. We omit the details of the calculations as they are routine. Let gkq = σ1k  σ1q −σkqσ1k σkk  . We now compute Pd k=1 P k̸=q gkq. There are three values that gkq takes: Case 1: k ̸= 1, q ̸= 1. Then gkq =  2d 2d−1 2 1 3d−1 2 1 + 1 3d−2  . Case 2: k = 1. Then gkq = σ1q −σ1qσ11/σ11 = 0. Case 3: q = 1. Then gkq = −  2d 2d−1 2 · 1 3d−1 ·  1 − 1 3d−1 − 1 3d−2  . Simplifying slightly, we have gkq ≤ −  2d 2d−1 2 · 1 3d−1 ·  1 − 2 3d−2  . In computing the sum over k and q we find (d−1)(d−2) terms corresponding to case Case 1, d−1 terms corresponding to Case 2, and d −1 terms corresponding to Case 3. Thus, we have d X k=1 X q̸=k gkq ≤(d −1)(d −2) ·  2d 2d −1 2 ·  1 3d −1 2 1 + 1 3d −2  −(d −1) ·  2d 2d −1 2 · 1 3d −1 ·  1 − 2 3d −2  . Rearranging, simplifying, and grouping negligible terms, we find d X k=1 X q̸=k gkq ≤−2 9 + O  1 d2  . 15 

--- Page 16 ---
Plugging all of the above into the formula for E[X2 1 | Rd +] results in E[X2 1 | Rd +] ≤σ11 −2 π 2 9 −O  1 d2  = 1 −4 9π + O 1 d  . Using Theorem 1.4, we then finally obtain P(Rd +) ≤2−d+1e−d/2e 1 2(O(1)+d−4d 9π) = O  2−de−2d 9π  as claimed. The following is now an immediate consequence of Lemmas 4.3 and 4.11, recalling that d = (n −3)/2. Lemma 4.12. For S as constructed above, G(S) = O  e−n 9π  . Proof. By Lemma 4.3, we need to multiply the bound from Lemma 4.11 by a factor 2dp det ˆΣ. It is easily seen from the proof of the latter lemma that this determinant is O(1). Finally, we combine all of the above for the last crucial lemma, from which our main result follows directly. Lemma 4.13. Let G be a complete graph on n = 2k + 1 ≥5 vertices, with edge weights drawn indepen- dently from U[0, 1] for each edge. Let T be any tour through G. The probability that T is 2-optimal is bounded from above by O   cn p (n −2)! ! , where c = p π 2 · e−1 9π < 1.2098. Proof. Let S be a set of 2-changes on G constructed as described above, and let ke be the number of 2-changes in S in which e ∈T participates. From Lemma 4.10 we have Y e∈T ke>0 1 ke = 1 n−1 2 −1 · 1 (n −3)! = O  1 (n −2)!  . Using this result in Lemma 4.1 together with Lemma 4.12 yields the claim. This leads to our last result (Theorem 1.3), using the fact that the number of tours on a complete graph is 1 2(n −1)!. 4.4 Numerical Experiment It seems unlikely that the bound in Theorem 1.3 is tight. A simple numerical estimate of G(S) already shows that it could be improved to O(1.0223n√ n!), but even this may be a coarse approximation; after all, in constructing S, we discard many 2-changes. To estimate the number of 2-optimal tours numerically, one could take a na¨ıve approach: simply fix a tour T, generate edge weights from U[0, 1], and check 2-optimality of T with these weights. By repeating this experiment we can estimate P(T is 2-optimal). However, since this probability is super-exponentially small (Lemma 4.13), this is rather inefficient. We can do better by taking a different view of the problem. Fix again an arbitrary tour T. We write the edge weights as a vector w ∈[0, 1]E. Given T, we can determine all n(n −3)/2 possible 2-changes on T. Local optimality of T means that all these 2-changes yield a negative improvement. Thus, for a 2-change that removes edges e1 and e2 and adds f1 and f2, this yields an inequality we1 + we2 −wf1 −wf2 ≤0. (4) Each possible 2-change on T yields such a constraint. Together with the constraints 0 ≤we ≤1 for each edge, this yields a convex polytope P embedded in Rm. Since the edge weights are i.i.d uniform random variables, P(T is 2-optimal) = vol(P), the |E|-dimensional volume of P. 16 

--- Page 17 ---
5 10 15 20 25 30 35 40 number of vertices 10 29 10 25 10 21 10 17 10 13 10 9 10 5 10 1 est. volume 1/ n! Figure 3: Estimated volume of the 2-opt polytope Pn, for different values of n, as computed by Volesti. For comparison, the function n 7→1/ √ n! is also plotted. We remark now that our approach through Lemma 4.1 is equivalent to bounding the volume of a polytope that contains P, by discarding some of the inequalities (Equation (4)). It may be possible to use methods from convex geometry to compute better estimates of vol(P); we leave this discussion to Section 5. Computing the volume of an arbitrary polytope is itself not an easy task: this problem is #P-hard in general, as shown by Dyer and Frieze [15]. In the same work however, they show that volume ap- proximation can be done efficiently by randomized algorithms. We use the open-source software package Volesti [10, 16] to numerically approximate the volume of P. For a range of different n, we compute the inequalities that define P, and output them in a format readable for Volesti. We use the ‘Cooling Balls’ algorithm of Volesti, with an error parameter of 0.001 (see the specification of Volesti [10] approximated vol(P) up to n = 40. The results of these computations are shown in Figure 3. 5 Discussion The result we present in Theorem 1.2 is to our knowledge the first hardness result for counting locally optimal solutions for a natural local search problem. We note that it is easy to show that counting the local optima is #P-hard for some local search problem. For instance, Johnson et al. [23] provided a local search problem whose locally optimal solutions are exactly the satisfying assignments of an instance of Boolean Satisfiability (plus one extra solution). However, their construction is rather artificial, whereas 2-opt is a heuristic often used in practice. Theorem 1.3 is to our knowledge the first non-trivial bound on the number of locally optimal solutions for a local search problem. It must be noted that we only proved Theorem 1.3 for specific values of n, namely n = 2k + 1 for k ∈N. This restriction simplifies mainly the construction of S, our set of chord- disjoint 2-changes. We believe that the results can be extended at the cost of some complexity in the proofs. For the sake of simplicity, we chose not to do so. The bound in Theorem 1.3 shows that in expectation, the number of 2-optimal tours in a random TSP instance is approximately the square root of the total number of tours. While still a rather large number, it is nonetheless a super-exponentially small fraction of the total number of tours. Limitations. A natural question concerns the tightness of the bound in Theorem 1.3. We have not suc- ceeded in constructing a lower bound for the number of 2-optimal tours. Presumably such a construction would be rather involved, since there is little structure in this random instance model. Nonetheless, we can still argue that Theorem 1.3 can be improved significantly from two directions: bounding G(S) and constructing S. Lemma 4.12 is far from optimal. A simple numerical experiment to estimate G(S) yields G(S) = 17 

--- Page 18 ---
O(1.226−n). This results in a bound of O(1.0223n√ n!) in Theorem 1.3. We also note that, even though our set S achieves essentially the largest number of chord-disjoint 2-changes possible on any tour, it may not be an optimal choice: different choices may lead to better sequences of values for ke. Using the trivial bound of G(S) ≤1 instead of Lemma 4.12 in Lemma 4.13, we would obtain in Theorem 1.3 a bound of approximately O(1.2534n√ n!). The difference with our bound is thus less than a factor of 1.04n, which is a rather minute improvement for the amount of trouble we went through to obtain it. We therefore regard the calculations leading to Lemma 4.12 more as a proof-of-concept that significant improvements are still possible to obtain rigorously, and as a demonstration of the effort required to achieve anything non-trivial. Another possible direction for improving the bound in Theorem 1.3 lies in polyhedron volume estima- tion. In Section 4.4, we defined a polytope P such that the volume of P is the probability that a tour on n vertices is 2-optimal. While computing the volume of a polytope is #P-hard in general [15], it may be possible to obtain an asymptotic formula for our specific case, as was done by Canfield and McKay for the well-studied Birkhoff polytope [9]. A conjecture. In light of these observations, and the estimate resulting from the numerical experiments, we conjecture the following. Conjecture. Let G be a complete graph on n vertices, with edge weights drawn independently from U[0, 1] for each edge. Then the expected number of 2-optimal tours on G is bounded from above by O( √ n!). The numerical data suggests that the expected number of tours may even be cn√ n! for some c < 1 (as opposed to c > 1 as in Theorem 1.3), although we could not perform the numerical experiments for large enough n to state this with confidence. References [1] E. Aarts and J. Korst. Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Computing. John Wiley & Sons, Inc., USA, 1989. [2] E. Aarts and J. K. Lenstra, editors. Local Search in Combinatorial Optimization. Princeton Univer- sity Press, 2003. [3] I. G. Abrahamson. Orthant Probabilities for the Quadrivariate Normal Distribution. The Annals of Mathematical Statistics, 35(4):1685–1703, Dec. 1964. [4] T. Amemiya. Multivariate Regression and Simultaneous Equation Models when the Dependent Variables Are Truncated Normal. Econometrica, 42(6):999–1012, 1974. [5] S. Arora and B. Barak. Computational Complexity: A Modern Approach. Cambridge University Press, Cambridge, 2009. [6] M. B. G. and S. Wilhelm. Moments Calculation for the Double Truncated Multivariate Normal Density, Sept. 2009. [7] M. Bˆocher. Certain cases in which the vanishing of the Wronskian is a sufficient condition for linear dependence. Transactions of the American Mathematical Society, 2(2):139–149, 1901. [8] U. A. Brodowsky and S. Hougardy. The Approximation Ratio of the 2-Opt Heuristic for the Euclidean Traveling Salesman Problem. In DROPS-IDN/v2/Document/10.4230/LIPIcs.STACS.2021.18. Schloss Dagstuhl – Leibniz-Zentrum f¨ur Informatik, 2021. [9] E. R. Canfield and B. D. McKay. The asymptotic volume of the Birkhoff polytope. Online Journal of Analytic Combinatorics, 2009. [10] A. Chalkis and V. Fisikopoulos. Volesti: Volume Approximation and Sampling for Convex Polytopes in R. The R Journal, 13(2):642–660, 2021. [11] B. Chandra, H. Karloff, and C. Tovey. New Results on the Old k-opt Algorithm for the Traveling Salesman Problem. SIAM Journal on Computing, 28(6):1998–2029, Jan. 1999. 18 

--- Page 19 ---
[12] Z. Chen, E. Mossel, and I. Zadik. Almost-Linear Planted Cliques Elude the Metropolis Process. In Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), Proceed- ings, pages 4504–4539. Society for Industrial and Applied Mathematics, Jan. 2023. [13] M. C. Cheng. The Orthant Probabilities of Four Gaussian Variates. The Annals of Mathematical Statistics, 40(1):152–161, 1969. [14] F. N. David. A note on the evaluation of the multivariate normal integral. Biometrika, 40(3-4):458– 459, Dec. 1953. [15] M. E. Dyer and A. M. Frieze. On the Complexity of Computing the Volume of a Polyhedron. SIAM Journal on Computing, 17(5):967–974, Oct. 1988. [16] I. Z. Emiris and V. Fisikopoulos. Practical Polytope Volume Approximation. ACM Trans. Math. Softw., 44(4):38:1–38:21, June 2018. [17] C. Engels and B. Manthey. Average-case approximation ratio of the 2-opt algorithm for the TSP. Operations Research Letters, 37(2):83–84, Mar. 2009. [18] M. Englert, H. R¨oglin, and B. V¨ocking. Worst Case and Probabilistic Analysis of the 2- Opt Algorithm for the TSP. Algorithmica, 68(1):190–264, Jan. 2014. Corrected version: https://arxiv.org/abs/2302.06889. [19] M. Englert, H. R¨oglin, and B. V¨ocking. Smoothed Analysis of the 2-Opt Algorithm for the General TSP. ACM Transactions on Algorithms, 13(1):10:1–10:15, Sept. 2016. [20] B. Hajek. Cooling Schedules for Optimal Annealing. Mathematics of Operations Research, 13(2):311– 329, 1988. [21] S. Hougardy, F. Zaiser, and X. Zhong. The approximation ratio of the 2-Opt Heuristic for the metric Traveling Salesman Problem. Operations Research Letters, 48(4):401–404, July 2020. [22] M. Jerrum. Large Cliques Elude the Metropolis Process. Random Structures & Algorithms, 3(4):347– 359, 1992. [23] D. S. Johnson, C. H. Papadimitriou, and M. Yannakakis. How easy is local search? Journal of Computer and System Sciences, 37(1):79–100, Aug. 1988. [24] R. M. Karp. Reducibility among Combinatorial Problems. In R. E. Miller, J. W. Thatcher, and J. D. Bohlinger, editors, Complexity of Computer Computations: Proceedings of a Symposium on the Complexity of Computer Computations, The IBM Research Symposia Series, pages 85–103. Springer US, Boston, MA, 1972. [25] M. K¨unnemann, B. Manthey, and R. Veenstra. Smoothed Analysis of the 2-Opt Heuristic for the TSP under Gaussian Noise, Aug. 2023. Comment: Combination of an ISAAC 2013 paper by Bodo Manthey and Rianne Veenstra and an ICALP 2015 paper by Marvin K\”unnemann and Bodo Manthey. The results of the ISAAC 2013 paper have been improved. [26] S. Lin and B. W. Kernighan. An Effective Heuristic Algorithm for the Traveling-Salesman Problem. Operations Research, 21(2):498–516, Apr. 1973. [27] B. Manthey and J. van Rhijn. Improved Smoothed Analysis of 2-Opt for the Euclidean TSP. In DROPS-IDN/v2/Document/10.4230/LIPIcs.ISAAC.2023.52. Schloss Dagstuhl – Leibniz-Zentrum f¨ur Informatik, 2023. [28] B. Manthey and R. Veenstra. Smoothed Analysis of the 2-Opt Heuristic for the TSP: Polynomial Bounds for Gaussian Noise. In L. Cai, S.-W. Cheng, and T.-W. Lam, editors, Algorithms and Computation, Lecture Notes in Computer Science, pages 579–589, Berlin, Heidelberg, 2013. Springer. Full, improved version: https://arxiv.org/abs/2308.00306. [29] A. Nolte and R. Schrader. A Note on the Finite Time Behavior of Simulated Annealing. Mathematics of Operations Research, 25(3):476–484, 2000. [30] L. G. Valiant. The Complexity of Enumeration and Reliability Problems. SIAM Journal on Com- puting, 8(3):410–421, Aug. 1979. [31] Q. Yuan. Answer to ”Determinant of a matrix involving factorials”, Nov. 2022. 19 

